{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pf96dkO-679R"
      },
      "outputs": [],
      "source": [
        "!pip install transformers nltk\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wm6Bef2W7AsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/LSBERT')\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "from simplify import simplify_word, load_fasttext, getWordCount"
      ],
      "metadata": {
        "id": "NQlkWZC77C57"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_name = \"bert-large-uncased-whole-word-masking\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForMaskedLM.from_pretrained(model_name).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.eval()\n",
        "\n",
        "# Load word embeddings + word frequencies\n",
        "fasttext_path = \"/content/drive/MyDrive/LSBERT/embeddings/crawl-300d-2M.vec\"\n",
        "word_freq_path = \"/content/drive/MyDrive/LSBERT/frequency_merge_wiki_child.txt\"\n",
        "\n",
        "fasttext_words, fasttext_vecs = load_fasttext(fasttext_path)\n",
        "word_freqs = getWordCount(word_freq_path)"
      ],
      "metadata": {
        "id": "lmRSTJYX7HUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The professor's lecture was extremely tedious and long-winded.\"\n",
        "target = \"tedious\"\n",
        "\n",
        "results = simplify_word(\n",
        "    sentence,\n",
        "    target,\n",
        "    tokenizer,\n",
        "    model,\n",
        "    fasttext_words,\n",
        "    fasttext_vecs,\n",
        "    word_freqs,\n",
        "    num_candidates=10\n",
        ")\n",
        "\n",
        "for word, lm_score, freq, sim in results:\n",
        "    print(f\"{word:<15} | LM Score: {lm_score:.4f} | Freq: {freq:.0f} | Similarity: {sim:.2f}\")\n"
      ],
      "metadata": {
        "id": "WxQUGEOE7cUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qm_7WgS778Qu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
